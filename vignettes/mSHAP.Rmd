---
title: "mSHAP"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mSHAP}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

The purpose of this vignette will be to explore different use cases for mSHAP.
It will focus heavily on insurance ratemaking, and will be based on the "AutoClaims" and "dataOhlsson" data sets that can be obtained in the `{insuranceData}` package, as demonstrated below:

```{r setup-r}
# library(mshap)
devtools::load_all()
library(reticulate)
library(insuranceData)
library(dplyr)
data("dataOhlsson")
```

In addition to the R libraries included above, we will need the additional python modules for these examples:

```{python setup-py}
import numpy as np
import pandas as pd
import shap
import sklearn.ensemble as sk
```

Numpy and Pandas are for data manipulation, shap allows us to calculate the SHAP values using TreeSHAP, and sklearn.ensemble is necessary as the models we will create will be random forest models using scikit-learn.

## Basic Use Case

First, we will demonstrate a simple use case on simulated data.
Suppose that we wish to be able to predict to total amount of money a consumer will spend on a subscription to a software product.
We might simulate 4 explanatory variables that looks like the following:

```{r}
set.seed(16)
age <- runif(1000, 18, 60)
income <- runif(1000, 50000, 150000)
married <- as.numeric(runif(1000, 0, 1) > 0.5)
sex <- as.numeric(runif(1000, 0, 1) > 0.5)
# For the sake of simplicity we will have these as numeric already, where 0 represents male and 1 represents female
```

Now because this is a contrived example, we will knowingly set the response variables as follows (suppose here that `cost_per_month` is usage based, so as to be continuous):

```{r}
cost_per_month <- (0.0006 * income - 0.2 * sex + 0.5 * married - 0.001 * age) + 10
num_months <- (0.0001 * income + 0.0001 * sex + 0.05 * married - 0.05 * age) + 3
```

Thus, we have our data.  We will combine the covariates into a single data frame for ease of use in python.

```{r}
X <- data.frame(age, income, married, sex)
```

The end goal of this exercise is to predict the total revenue from the given customer, which mathematically will be `cost_per_month * num_months`.
Instead of multiplying these two vectors together initially, we will instead create two models: one to predict `cost_per_month` and the other to predict `num_months`. We can then multiply the output of the two models together to get our predictions.

We now move over to python to create our two models and predict on the training sets:
```{python}
X = r.X
y1 = r.cost_per_month
y2 = r.num_months

cpm_mod = sk.RandomForestRegressor(n_estimators = 100, max_depth = 10, max_features = 2)
cpm_mod.fit(X, y1)

nm_mod = sk.RandomForestRegressor(n_estimators = 100, max_depth = 10, max_features = 2)
nm_mod.fit(X, y2)

cpm_preds = cpm_mod.predict(X)
nm_preds = nm_mod.predict(X)

tot_rev = cpm_preds * nm_preds
```

We will now proceed to use TreeSHAP and subsequently mSHAP to explain the ultimate model predictions.

```{python}
# because these are tree-based models, shap.Explainer uses TreeSHAP to calculate
# fast, exact SHAP values for each model individually
cpm_ex = shap.Explainer(cpm_mod)
cpm_shap = cpm_ex.shap_values(X)
cpm_expected_value = cpm_ex.expected_value

nm_ex = shap.Explainer(nm_mod)
nm_shap = nm_ex.shap_values(X)
nm_expected_value = nm_ex.expected_value
```

```{r}
final_shap <- mshap(
  shap_1 = py$cpm_shap, 
  shap_2 = py$nm_shap, 
  ex_1 = py$cpm_expected_value, 
  ex_2 = py$nm_expected_value
)

head(final_shap$shap_vals)

final_shap$expected_value
```

As a check, you can see that the expected value for mSHAP is indeed the expected value of the model across the training data.
```{r}
mean(py$tot_rev)
```



We now have calculated the mSHAP values for the multiplied model outputs! This will allow us to explain our final model.

The mSHAP package comes with additional functions that can be used to visualize SHAP values in R.
What is show here are the default outputs, but these functions return `{ggplot2}` objects that are easily customizable.

```{r, fig.width=5, fig.height=5,fig.align='center'}
summary_plot(
  variable_values = X,
  shap_values = final_shap$shap_vals, 
  names = c("age", "income", "married", "sex") # this is optional, since X has column names
)
```

```{r, fig.width=5, fig.height=5,fig.align='center'}
observation_plot(
  variable_values = X[46,],
  shap_values = final_shap$shap_vals[46,],
  expected_value = final_shap$expected_value,
  names = c("age", "income", "married", "sex")
)
```





## Use Case on Ohlsson Data

We will now work through a little bit of a different use case, one specific to the insurance industry.
In it, we will create a two-part model to predict the ultimate cost of the policy by using the first part of the model to predict the severity and the second part of the model to predict the frequency.
Our frequency model will be a multinomial model, which will allow us to demonstrate using mSHAP with a multinomial output.

### Step 1: Predict the Severity

Our first model will predict the severity, or the cost per claim.

```{r}
dataOhlsson %>% colnames()
```

We will filter for only policies with a claim, then calculate severity, and because these colnames are not in english, we will rename them. Summaries of each variables are given as well.

```{r}
sev <- dataOhlsson %>%
  filter(antskad > 0) %>%
  mutate(severity = skadkost / antskad) %>%
  select(
    severity,
    age = agarald,
    gender = kon,
    geographic_zone = zon,
    vehicle_age = fordald
  )
summary(sev$severity)
summary(sev$exposure)
summary(sev$age)
summary(sev$vehicle_age)
sev %>% count(gender)
sev %>% count(geographic_zone)
```

We will now use python to create a model and shap explainer to predict the severity after further refining the data we need in R.

```{r}
X <- sev %>%
  mutate(
    is_male = gender == "M"
  ) %>%
  select(-severity, -gender)
severity <- sev$severity
```


```{python}
mod_dat = r.X
sev = r.severity

sev_mod = sk.RandomForestRegressor(n_estimators = 100, max_depth = 10, max_features = 2)
sev_mod.fit(mod_dat, sev)

sev_preds = sev_mod.predict(mod_dat)

sev_ex = shap.Explainer(sev_mod)
sev_expected_val = sev_ex.expected_value
sev_preds_explained = sev_ex.shap_values(mod_dat)
```


### Step 2: Predict the Freequency

The next step is to create a model that predicts the frequency of a claim.  In this case, the possible values are 0, 1, and 2.
Technically, it is possible to have more than 2 claims, but we will consider the probability so small as to be negligble.
In order to create this model, we will use the same variables as before, but weight by the exposure column.
Furthermore, we will downsample the rows with 0 claims while upsampling the rows with 1 and 2 claims, so we have a balanced data set.

```{r}
freq_unbalanced <- dataOhlsson %>%
  select(
    claims = antskad,
    exposure = duration,
    age = agarald,
    gender = kon,
    geographic_zone = zon,
    vehicle_age = fordald
  )
freq_0 = freq_unbalanced %>%
  filter(claims == 0) %>%
  sample_n(8000)
freq_1 = freq_unbalanced %>%
  filter(claims == 1) %>%
  sample_n(8000, replace = TRUE)
freq_2 = freq_unbalanced %>%
  filter(claims == 2) %>%
  sample_n(8000, replace = TRUE)

freq <- freq_0 %>% 
  bind_rows(freq_1) %>%
  bind_rows(freq_2) %>%
  mutate(claims = as.factor(claims))
```

Now to python for the model after creating our model data and response objects.
Note that here we will also pass the whole dataset to python for predicting on and calculating SHAP values.

```{r}
X <- freq %>%
  mutate(
    is_male = gender == "M"
  ) %>%
  select(-gender, -claims)
claims = freq$claims
actual_dat <- freq_unbalanced %>%
  mutate(
    is_male = gender == "M"
  ) %>%
  select(-gender, -claims)
```

```{python}
mod_dat = r.X
claims = r.claims
actual_dat = r.actual_dat

freq_mod = sk.RandomForestClassifier(n_estimators = 100, max_depth = 10, max_features = 2)
freq_mod.fit(mod_dat, claims)

freq_preds = sev_mod.predict(actual_dat)

freq_ex = shap.Explainer(freq_mod)
freq_expected_val = freq_ex.expected_value
freq_preds_explained = freq_ex.shap_values(mod_dat)
```


### Step 3: Combine the Models

### Step 4: Apply mSHAP

### Step 5: Visualize the Results

## Conclusion
